---
title: python 爬蟲學習記錄
date: 2018-04-07 12:27:56
categories: python
---
python 程式語言的著名應用中莫過於就是寫網路爬蟲了，以下記錄我一些學習的心得。
首先，要利用 python 寫一隻爬蟲程式，裡面最重要的就是以下兩個 python 套件:
1. [**requests**](http://docs.python-requests.org/en/master/)
2. [**BeautifulSoup**](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

這兩個套件可以說是構成 python 網路爬蟲的基礎，``requests`` 套件用來拜訪要爬資料的網站，並且取得爬資料網頁的整個 html 內容，``BeautifulSoup`` 套件則是更進一步的剖析取回的 html 文檔內容，像是選擇特定幾個 tag 來取回想爬的資料。
以下為簡單的爬蟲範例，目標是爬一個登山資訊網站的資訊紀錄內容：

```python=
import requests
from user_agent import generate_user_agent
import bs4

def hiking_crawler():
    url = 'https://www.keepon.com.tw/forum-1-1.html'
    headers = {
        'User-Agent': generate_user_agent(device_type="desktop", 
                                          os=('mac', 'linux'))
    }
    response = requests.get(url, headers=headers)
    page_content = bs4.BeautifulSoup(response.content, 'lxml')
    hyperlink_list = page_content.select('#forum_list .media-body > h4 > a')

    for hyperlink in hyperlink_list:
        print(hyperlink.contents)

if __name__ == '__main__':
    hiking_crawler()
```
第 8 行的 ``generate_user_agent`` 是用來模擬產生 http request header 中 User-Agent 的相關資訊，用來將爬蟲程式假裝成一般的瀏覽器使用者，如果沒有刻意加這個的話，User-Agent 預設就會透露爬蟲程式的資訊了，可能會被一些不想被爬的網站擋掉。第 12、13 行利用 ``BeautifulSoup`` 套件來將回應的 html 內容轉成專屬型別物件來進行之後的元素選擇操作，這裡我是用來取得登山資訊網站的超連結元素內容。最後的執行結果如下：

```
['劍龍稜新闢捷徑路線（避開重汙染區）＋劍龍稜及鋸齒稜B段峭壁登架新繩']
['台南部分基石巡禮--大屯寮、山寮、林鳳營(未遇)、上茄苳、平頂山、六甲、頂秀祐與烏子嶺']
['北大武杷宇森出比魯溫泉']
['新北雙溪 蝙蝠山 苕谷瀑布 苕谷坑古道 苕谷坑山/東南峰 梅竹蹊山']
['新北雙溪 探訪古蹟古厝']
['水頭谷山東南峰']
['阿白縱走']
['坑內路森林步道/受天宮/北天宮行程 ']
['佛頂山朝聖寺/拐子湖山行程']
['連續摃龜的菜刀崙山北峰與車閂寮西北峰－大台北基石巡禮篇']
['20170624-27_干卓萬3.0之山豬驚魂']
['20171209-1214_南一三星好刺刺刺刺']
```
感想就是 ``BeautifulSoup`` 套件真是一個好東西。
參考：
https://www.kdnuggets.com/2018/02/web-scraping-tutorial-python.html